{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "he-snetiment.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyB5_J6YyvD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "182a878c-79c4-4821-9238-d59233f50bd1"
      },
      "source": [
        "!pip install git+https://github.com/hiredscorelabs/tamnun-ml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hiredscorelabs/tamnun-ml\n",
            "  Cloning https://github.com/hiredscorelabs/tamnun-ml to /tmp/pip-req-build-kuuvwuf3\n",
            "  Running command git clone -q https://github.com/hiredscorelabs/tamnun-ml /tmp/pip-req-build-kuuvwuf3\n",
            "Collecting numpy==1.15.4 (from tamnun==0.1.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 3.4MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.20.2 (from tamnun==0.1.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.6/dist-packages (from tamnun==0.1.0) (1.1.0)\n",
            "Collecting pytorch-transformers (from tamnun==0.1.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.2->tamnun==0.1.0) (1.3.0)\n",
            "Collecting regex (from pytorch-transformers->tamnun==0.1.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun==0.1.0) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun==0.1.0) (1.9.199)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->tamnun==0.1.0) (2.21.0)\n",
            "Collecting sentencepiece (from pytorch-transformers->tamnun==0.1.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun==0.1.0) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.199 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun==0.1.0) (1.12.199)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->tamnun==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun==0.1.0) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->tamnun==0.1.0) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-transformers->tamnun==0.1.0) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-transformers->tamnun==0.1.0) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.199->boto3->pytorch-transformers->tamnun==0.1.0) (1.12.0)\n",
            "Building wheels for collected packages: tamnun, regex\n",
            "  Building wheel for tamnun (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tamnun: filename=tamnun-0.1.0-cp36-none-any.whl size=9440 sha256=b96140d6c9cb8ba19803f91570c9102afe6cc0a375d5bbc084aed6105220e2ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v5dq_2c0/wheels/3a/d7/c7/e7957cdb3f1e9185549672ac4389548eacf6b90e07c88a46c7\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604153 sha256=691351b42ec4015e5e0e4899d712a564ea9be511a297b257a2cb799603ad4ef7\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built tamnun regex\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, scikit-learn, regex, sentencepiece, pytorch-transformers, tamnun\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "Successfully installed numpy-1.15.4 pytorch-transformers-1.0.0 regex-2019.6.8 scikit-learn-0.20.2 sentencepiece-0.1.82 tamnun-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDdBs7bIy1Gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "82b46371-d1a4-4995-937b-4b94b0f21789"
      },
      "source": [
        "!git clone https://github.com/omilab/Neural-Sentiment-Analyzer-for-Modern-Hebrew"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Neural-Sentiment-Analyzer-for-Modern-Hebrew'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 33\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBzh0rJdzOSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv Neural-Sentiment-Analyzer-for-Modern-Hebrew/data data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LqDmsWry6Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "from tamnun.bert import BertVectorizer, BertClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShsBSDSdzCZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    data = list(codecs.open(filename, 'r', 'utf-8').readlines())\n",
        "    x, y = zip(*[d.strip().split('\\t') for d in data])\n",
        "    x = np.asarray(list(x))\n",
        "    #y = to_categorical(y, 3)\n",
        "    \n",
        "    return x, np.array(list(map(int, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVFJ2rHMzDut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77b940b9-212e-4654-8696-8c8f30dd5c99"
      },
      "source": [
        "train_tokens, train_tags = load_data('data/token_train.tsv')\n",
        "test_tokens, test_tags = load_data('data/token_test.tsv')\n",
        "train_tokens.shape, train_tags.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10244,), (10244,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGxY9rzKzFGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9ae41359-a7c3-4bbe-ef26-7cda8b25825f"
      },
      "source": [
        "vectorizer = BertVectorizer(do_truncate=True, bert_model='bert-base-multilingual-cased').fit(train_tokens)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
            "100%|██████████| 995526/995526 [00:00<00:00, 5661655.25B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfcUa9EtzZ4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = vectorizer.transform(train_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0858YMNGz9_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dfc2b825-f056-4c10-e351-3eb89e99bc5f"
      },
      "source": [
        "clf = BertClassifier(num_of_classes=3, bert_model_name='bert-base-multilingual-cased', lr=1e-5).fit(train_X, train_tags)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5:\n",
            "2560/2561 batch loss: 0.30547451972961426 avg loss: 0.41300118063190683\n",
            "Epoch 2/5:\n",
            "2560/2561 batch loss: 0.057198941707611084 avg loss: 0.24542082355083875\n",
            "Epoch 3/5:\n",
            "2560/2561 batch loss: 0.21260246634483337 avg loss: 0.1486284119258491\n",
            "Epoch 4/5:\n",
            "2560/2561 batch loss: 0.06112164258956909 avg loss: 0.09607804239331535\n",
            "Epoch 5/5:\n",
            "2560/2561 batch loss: 0.020296812057495117 avg loss: 0.0736653968104158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeUS8eeHPzbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = vectorizer.transform(test_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjBqXSHB0aBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = clf.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxSHuMSSPxsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLSsXZV0QN23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "75684f05-2977-4c5a-e4d6-a77aa321bc79"
      },
      "source": [
        "print('Accuracy:', accuracy_score(test_tags, predicted))\n",
        "print(classification_report(test_tags, predicted))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.928515625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      1698\n",
            "           1       0.91      0.89      0.90       790\n",
            "           2       0.62      0.61      0.62        72\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      2560\n",
            "   macro avg       0.83      0.82      0.82      2560\n",
            "weighted avg       0.93      0.93      0.93      2560\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HpQJYnyQWOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}